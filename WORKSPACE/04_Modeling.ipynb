{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3970f2c",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning Modeling\n",
    "## Ensemble Methods for Food Health Classification\n",
    "\n",
    "This notebook implements advanced machine learning approaches including:\n",
    "- Multiple algorithm comparison (Random Forest, XGBoost, Neural Networks)\n",
    "- Ensemble methods and model stacking\n",
    "- Advanced cross-validation strategies\n",
    "- Feature importance analysis\n",
    "- Model interpretability (SHAP values)\n",
    "\n",
    "Goal: Classify foods as healthy/unhealthy using comprehensive feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c256f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced ML libraries loaded\n"
     ]
    }
   ],
   "source": [
    "# Core ML libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, StratifiedKFold, \n",
    "    GridSearchCV, RandomizedSearchCV\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "# Advanced ML libraries\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Model interpretation\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SHAP_AVAILABLE = False\n",
    "    print(\"SHAP not available - install with: pip install shap\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure Plotly for both HTML and PNG export\n",
    "import plotly.io as pio\n",
    "pio.kaleido.scope.mathjax = None\n",
    "\n",
    "# Setup directories\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "results_dir = Path('../RESULTS')\n",
    "models_dir = results_dir / 'models'\n",
    "figures_dir = results_dir / 'figures'\n",
    "reports_dir = results_dir / 'reports'\n",
    "\n",
    "for directory in [results_dir, models_dir, figures_dir, reports_dir]:\n",
    "    directory.mkdir(exist_ok=True)\n",
    "\n",
    "# Helper function for dual-format plot saving\n",
    "def save_plotly_figure(fig, filename):\n",
    "    \"\"\"Save plotly figure in both HTML and PNG formats\"\"\"\n",
    "    try:\n",
    "        # Save interactive HTML version\n",
    "        fig.write_html(figures_dir / f'{filename}.html')\n",
    "        \n",
    "        # Save static PNG version\n",
    "        fig.write_image(figures_dir / f'{filename}.png', width=1200, height=800, scale=2)\n",
    "        print(f\"Saved plot: {filename}.html and {filename}.png\")\n",
    "    except Exception as e:\n",
    "        # Fallback to HTML only if PNG export fails\n",
    "        fig.write_html(figures_dir / f'{filename}.html')\n",
    "        print(f\"Saved plot: {filename}.html only (PNG export failed: {e})\")\n",
    "\n",
    "print(\"Advanced ML libraries loaded\")\n",
    "print(\"Plotly configured for both HTML and PNG export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7c4fa0",
   "metadata": {},
   "source": [
    "## Target Variable Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96fa82f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health classification system ready\n"
     ]
    }
   ],
   "source": [
    "class HealthClassifier:\n",
    "    \"\"\"Advanced health classification system\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Health scoring weights\n",
    "        self.health_weights = {\n",
    "            'ingredient_health_score': 0.3,\n",
    "            'preservatives_score': -0.2,\n",
    "            'artificial_colors_score': -0.25,\n",
    "            'artificial_sweeteners_score': -0.15,\n",
    "            'natural_sweeteners_score': 0.1,\n",
    "            'whole_grains_score': 0.2,\n",
    "            'healthy_fats_score': 0.15,\n",
    "            'processing_claims_count': 0.1,\n",
    "            'complexity_score': -0.1,\n",
    "            'category_health_score': 0.2\n",
    "        }\n",
    "    \n",
    "    def create_health_labels(self, features_df):\n",
    "        \"\"\"Create binary health labels using weighted scoring\"\"\"\n",
    "        health_score = np.zeros(len(features_df))\n",
    "        \n",
    "        for feature, weight in self.health_weights.items():\n",
    "            if feature in features_df.columns:\n",
    "                # Normalize feature to 0-1 scale\n",
    "                feature_values = features_df[feature].fillna(0)\n",
    "                if feature_values.max() > 0:\n",
    "                    normalized = feature_values / feature_values.max()\n",
    "                    health_score += weight * normalized\n",
    "        \n",
    "        # Convert to binary labels (top 30% as healthy)\n",
    "        threshold = np.percentile(health_score, 70)\n",
    "        health_labels = (health_score >= threshold).astype(int)\n",
    "        \n",
    "        return health_labels, health_score\n",
    "    \n",
    "    def get_feature_importance_weights(self):\n",
    "        \"\"\"Return feature importance weights for interpretation\"\"\"\n",
    "        return self.health_weights\n",
    "\n",
    "health_classifier = HealthClassifier()\n",
    "print(\"Health classification system ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89380035",
   "metadata": {},
   "source": [
    "## Model Pipeline & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b61ef28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced model pipeline ready\n"
     ]
    }
   ],
   "source": [
    "class AdvancedModelPipeline:\n",
    "    \"\"\"Advanced machine learning pipeline with multiple algorithms\"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.random_state = random_state\n",
    "        self.models = {}\n",
    "        self.best_params = {}\n",
    "        self.results = {}\n",
    "        \n",
    "        # Define model configurations\n",
    "        self.model_configs = {\n",
    "            'random_forest': {\n",
    "                'model': RandomForestClassifier(random_state=random_state),\n",
    "                'params': {\n",
    "                    'n_estimators': [100, 200, 300],\n",
    "                    'max_depth': [10, 20, None],\n",
    "                    'min_samples_split': [2, 5, 10],\n",
    "                    'min_samples_leaf': [1, 2, 4]\n",
    "                }\n",
    "            },\n",
    "            'xgboost': {\n",
    "                'model': xgb.XGBClassifier(random_state=random_state, eval_metric='logloss'),\n",
    "                'params': {\n",
    "                    'n_estimators': [100, 200, 300],\n",
    "                    'max_depth': [3, 6, 9],\n",
    "                    'learning_rate': [0.01, 0.1, 0.2],\n",
    "                    'subsample': [0.8, 0.9, 1.0]\n",
    "                }\n",
    "            },\n",
    "            'neural_network': {\n",
    "                'model': MLPClassifier(random_state=random_state, max_iter=1000),\n",
    "                'params': {\n",
    "                    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "                    'activation': ['relu', 'tanh'],\n",
    "                    'alpha': [0.0001, 0.001, 0.01],\n",
    "                    'learning_rate': ['constant', 'adaptive']\n",
    "                }\n",
    "            },\n",
    "            'logistic_regression': {\n",
    "                'model': LogisticRegression(random_state=random_state, max_iter=1000),\n",
    "                'params': {\n",
    "                    'C': [0.1, 1, 10, 100],\n",
    "                    'penalty': ['l1', 'l2'],\n",
    "                    'solver': ['liblinear', 'saga']\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def train_individual_models(self, X_train, y_train, X_test, y_test, cv_folds=5):\n",
    "        \"\"\"Train and tune individual models\"\"\"\n",
    "        print(\"Training individual models with hyperparameter tuning...\")\n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        for name, config in self.model_configs.items():\n",
    "            print(f\"   ðŸ”§ Tuning {name}...\")\n",
    "            \n",
    "            # Randomized search for efficiency\n",
    "            search = RandomizedSearchCV(\n",
    "                config['model'],\n",
    "                config['params'],\n",
    "                n_iter=20,  # Limit iterations for speed\n",
    "                cv=cv,\n",
    "                scoring='f1',\n",
    "                n_jobs=-1,\n",
    "                random_state=self.random_state\n",
    "            )\n",
    "            \n",
    "            search.fit(X_train, y_train)\n",
    "            \n",
    "            # Store best model and parameters\n",
    "            self.models[name] = search.best_estimator_\n",
    "            self.best_params[name] = search.best_params_\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = search.best_estimator_.predict(X_test)\n",
    "            y_pred_proba = search.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            self.results[name] = {\n",
    "                'accuracy': accuracy_score(y_test, y_pred),\n",
    "                'precision': precision_score(y_test, y_pred),\n",
    "                'recall': recall_score(y_test, y_pred),\n",
    "                'f1': f1_score(y_test, y_pred),\n",
    "                'auc': roc_auc_score(y_test, y_pred_proba),\n",
    "                'cv_score': search.best_score_\n",
    "            }\n",
    "            \n",
    "            print(f\"     {name}: F1={self.results[name]['f1']:.3f}, AUC={self.results[name]['auc']:.3f}\")\n",
    "        \n",
    "        return self.models, self.results\n",
    "    \n",
    "    def create_ensemble_models(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"Create ensemble models using voting and stacking\"\"\"\n",
    "        print(\"ðŸ”— Creating ensemble models...\")\n",
    "        \n",
    "        # Voting Classifier\n",
    "        voting_clf = VotingClassifier(\n",
    "            estimators=[\n",
    "                ('rf', self.models['random_forest']),\n",
    "                ('xgb', self.models['xgboost']),\n",
    "                ('lr', self.models['logistic_regression'])\n",
    "            ],\n",
    "            voting='soft'\n",
    "        )\n",
    "        \n",
    "        voting_clf.fit(X_train, y_train)\n",
    "        self.models['voting_ensemble'] = voting_clf\n",
    "        \n",
    "        # Stacking Classifier\n",
    "        stacking_clf = StackingClassifier(\n",
    "            estimators=[\n",
    "                ('rf', self.models['random_forest']),\n",
    "                ('xgb', self.models['xgboost']),\n",
    "                ('nn', self.models['neural_network'])\n",
    "            ],\n",
    "            final_estimator=LogisticRegression(random_state=self.random_state),\n",
    "            cv=5\n",
    "        )\n",
    "        \n",
    "        stacking_clf.fit(X_train, y_train)\n",
    "        self.models['stacking_ensemble'] = stacking_clf\n",
    "        \n",
    "        # Evaluate ensemble models\n",
    "        for ensemble_name in ['voting_ensemble', 'stacking_ensemble']:\n",
    "            y_pred = self.models[ensemble_name].predict(X_test)\n",
    "            y_pred_proba = self.models[ensemble_name].predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            self.results[ensemble_name] = {\n",
    "                'accuracy': accuracy_score(y_test, y_pred),\n",
    "                'precision': precision_score(y_test, y_pred),\n",
    "                'recall': recall_score(y_test, y_pred),\n",
    "                'f1': f1_score(y_test, y_pred),\n",
    "                'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "            }\n",
    "            \n",
    "            print(f\"   {ensemble_name}: F1={self.results[ensemble_name]['f1']:.3f}, AUC={self.results[ensemble_name]['auc']:.3f}\")\n",
    "        \n",
    "        return self.models\n",
    "    \n",
    "    def get_best_model(self):\n",
    "        \"\"\"Return the best performing model based on F1 score\"\"\"\n",
    "        best_model_name = max(self.results.keys(), key=lambda x: self.results[x]['f1'])\n",
    "        return best_model_name, self.models[best_model_name]\n",
    "    \n",
    "    def save_models(self):\n",
    "        \"\"\"Save all trained models to disk\"\"\"\n",
    "        print(\"Saving trained models...\")\n",
    "        \n",
    "        for model_name, model in self.models.items():\n",
    "            model_path = models_dir / f'{model_name}_model.pkl'\n",
    "            joblib.dump(model, model_path)\n",
    "            print(f\"  Saved {model_name} to {model_path}\")\n",
    "        \n",
    "        # Save results summary\n",
    "        results_path = models_dir / 'model_results.json'\n",
    "        import json\n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(self.results, f, indent=2)\n",
    "        \n",
    "        print(f\"  Saved results summary to {results_path}\")\n",
    "        return len(self.models)\n",
    "\n",
    "print(\"Advanced model pipeline ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29033bd",
   "metadata": {},
   "source": [
    "## Model Evaluation & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6c7983b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation framework ready\n"
     ]
    }
   ],
   "source": [
    "def create_comprehensive_evaluation(results, models, X_test, y_test, feature_names):\n",
    "    \"\"\"Create comprehensive model evaluation dashboard\"\"\"\n",
    "    \n",
    "    # 1. Performance Comparison Chart\n",
    "    metrics_df = pd.DataFrame(results).T\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=['F1 Score', 'Accuracy', 'Precision', 'Recall'],\n",
    "        specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "               [{\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n",
    "    )\n",
    "    \n",
    "    metrics = ['f1', 'accuracy', 'precision', 'recall']\n",
    "    positions = [(1, 1), (1, 2), (2, 1), (2, 2)]\n",
    "    \n",
    "    for metric, (row, col) in zip(metrics, positions):\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=metrics_df.index,\n",
    "                y=metrics_df[metric],\n",
    "                name=metric.title(),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row, col=col\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Model Performance Comparison\",\n",
    "        height=600\n",
    "    )\n",
    "    save_plotly_figure(fig, 'model_performance_comparison')\n",
    "    fig.show()\n",
    "    \n",
    "    # 2. Feature Importance (for tree-based models)\n",
    "    if 'random_forest' in models:\n",
    "        rf_importance = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': models['random_forest'].feature_importances_\n",
    "        }).sort_values('importance', ascending=False).head(15)\n",
    "        \n",
    "        fig_importance = px.bar(\n",
    "            rf_importance,\n",
    "            x='importance',\n",
    "            y='feature',\n",
    "            orientation='h',\n",
    "            title=\"Top 15 Feature Importances (Random Forest)\"\n",
    "        )\n",
    "        save_plotly_figure(fig_importance, 'feature_importance_rf')\n",
    "        fig_importance.show()\n",
    "    \n",
    "    # 3. Results Summary Table\n",
    "    print(\"\\n MODEL PERFORMANCE SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    summary_df = metrics_df[['f1', 'accuracy', 'precision', 'recall', 'auc']].round(3)\n",
    "    print(summary_df.to_string())\n",
    "    \n",
    "    # Best model recommendation\n",
    "    best_f1_model = summary_df['f1'].idxmax()\n",
    "    best_auc_model = summary_df['auc'].idxmax()\n",
    "    \n",
    "    print(f\"\\nBEST MODELS:\")\n",
    "    print(f\"   Best F1 Score: {best_f1_model} ({summary_df.loc[best_f1_model, 'f1']:.3f})\")\n",
    "    print(f\"   Best AUC Score: {best_auc_model} ({summary_df.loc[best_auc_model, 'auc']:.3f})\")\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "print(\"Evaluation framework ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c2bef9",
   "metadata": {},
   "source": [
    "## Model Interpretability with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4729411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model interpretability framework ready\n"
     ]
    }
   ],
   "source": [
    "def analyze_model_interpretability(model, X_test, feature_names):\n",
    "    \"\"\"Analyze model interpretability using SHAP values\"\"\"\n",
    "    \n",
    "    if not SHAP_AVAILABLE:\n",
    "        print(\"SHAP not available for model interpretability analysis\")\n",
    "        return\n",
    "    \n",
    "    print(\"Analyzing model interpretability with SHAP...\")\n",
    "    \n",
    "    try:\n",
    "        # Create SHAP explainer\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            explainer = shap.Explainer(model, X_test.sample(100))\n",
    "            shap_values = explainer(X_test.sample(200))\n",
    "            \n",
    "            # Summary plot\n",
    "            shap.summary_plot(shap_values, X_test.sample(200), feature_names=feature_names, show=False)\n",
    "            plt.title(\"SHAP Feature Importance Summary\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Waterfall plot for a single prediction\n",
    "            shap.waterfall_plot(shap_values[0], show=False)\n",
    "            plt.title(\"SHAP Waterfall Plot (Single Prediction)\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"SHAP analysis complete\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"SHAP analysis failed: {str(e)}\")\n",
    "\n",
    "print(\"Model interpretability framework ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84064058",
   "metadata": {},
   "source": [
    "## Main Modeling Pipeline Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "417215b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete modeling pipeline ready for execution\n",
      "   Run: pipeline, summary, best_model = run_complete_modeling_pipeline(features_df)\n"
     ]
    }
   ],
   "source": [
    "# This cell would execute the full modeling pipeline with real data\n",
    "def run_complete_modeling_pipeline(features_df, test_size=0.2):\n",
    "    \"\"\"Execute the complete advanced modeling pipeline\"\"\"\n",
    "    \n",
    "    print(\"STARTING ADVANCED MODELING PIPELINE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Create target variable\n",
    "    print(\"\\n Creating health classification labels...\")\n",
    "    y, health_scores = health_classifier.create_health_labels(features_df)\n",
    "    \n",
    "    # Select features for modeling\n",
    "    feature_columns = [\n",
    "        'brand_product_count', 'brand_category_diversity', 'brand_premium_score',\n",
    "        'preservatives_score', 'artificial_colors_score', 'artificial_sweeteners_score',\n",
    "        'natural_sweeteners_score', 'whole_grains_score', 'healthy_fats_score',\n",
    "        'processing_claims_count', 'ingredient_count', 'complexity_score',\n",
    "        'ingredient_health_score', 'category_frequency', 'category_health_score'\n",
    "    ]\n",
    "    \n",
    "    # Filter available features\n",
    "    available_features = [f for f in feature_columns if f in features_df.columns]\n",
    "    X = features_df[available_features].fillna(0)\n",
    "    \n",
    "    print(f\"   Using {len(available_features)} features for modeling\")\n",
    "    print(f\"   Target distribution: {np.bincount(y)} (Healthy: {y.sum()}, Unhealthy: {len(y)-y.sum()})\")\n",
    "    \n",
    "    # 2. Train-test split\n",
    "    print(\"\\nSplitting data...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # 3. Initialize and run pipeline\n",
    "    print(\"\\n Training models...\")\n",
    "    pipeline = AdvancedModelPipeline()\n",
    "    \n",
    "    # Train individual models\n",
    "    models, results = pipeline.train_individual_models(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # Create ensemble models\n",
    "    ensemble_models = pipeline.create_ensemble_models(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # 4. Comprehensive evaluation\n",
    "    print(\"\\n Model evaluation...\")\n",
    "    summary_df = create_comprehensive_evaluation(\n",
    "        pipeline.results, pipeline.models, X_test, y_test, available_features\n",
    "    )\n",
    "    \n",
    "    # 5. Model interpretability\n",
    "    print(\"\\n Model interpretability analysis...\")\n",
    "    best_model_name, best_model = pipeline.get_best_model()\n",
    "    analyze_model_interpretability(best_model, X_test, available_features)\n",
    "    \n",
    "    print(f\"\\n MODELING PIPELINE COMPLETE!\")\n",
    "    print(f\"   Best model: {best_model_name}\")\n",
    "    print(f\"   Best F1 score: {pipeline.results[best_model_name]['f1']:.3f}\")\n",
    "    \n",
    "    return pipeline, summary_df, best_model_name\n",
    "\n",
    "# Placeholder for execution with real data\n",
    "print(\"Complete modeling pipeline ready for execution\")\n",
    "print(\"   Run: pipeline, summary, best_model = run_complete_modeling_pipeline(features_df)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc08293",
   "metadata": {},
   "source": [
    "## Modeling Summary & Insights\n",
    "\n",
    "### Advanced ML Pipeline Features:\n",
    "\n",
    "1. **Multi-Algorithm Comparison**:\n",
    "   - Random Forest with hyperparameter tuning\n",
    "   - XGBoost with gradient boosting optimization\n",
    "   - Neural Networks with adaptive learning\n",
    "   - Logistic Regression baseline\n",
    "\n",
    "2. **Ensemble Methods**:\n",
    "   - Voting Classifier (soft voting)\n",
    "   - Stacking Classifier with meta-learner\n",
    "   - Performance comparison across methods\n",
    "\n",
    "3. **Advanced Evaluation**:\n",
    "   - Stratified cross-validation\n",
    "   - Multiple metrics (F1, AUC, Precision, Recall)\n",
    "   - Feature importance analysis\n",
    "   - Model interpretability with SHAP\n",
    "\n",
    "### Expected Outcomes:\n",
    "- **Model Performance**: F1 scores likely 0.75-0.85 range\n",
    "- **Key Features**: Ingredient health scores, preservatives, processing claims\n",
    "- **Best Algorithm**: Likely ensemble methods or XGBoost\n",
    "- **Interpretability**: Clear feature contribution analysis\n",
    "\n",
    "### Business Value:\n",
    "- Automated food health classification\n",
    "- Ingredient quality assessment\n",
    "- Brand positioning insights\n",
    "- Consumer health guidance\n",
    "\n",
    "**Next Notebook**: `05_Evaluation.ipynb` - Detailed model validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dd10f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACHINE LEARNING PIPELINE EXECUTION\n",
      "========================================\n",
      "Step 1: Loading engineered features...\n",
      "Loaded 10,000 products with 44 features\n",
      "Step 2: Creating health labels...\n",
      "Created health labels: 3323 healthy, 6677 unhealthy\n",
      "Using 15 features\n",
      "Training set: 8000 samples\n",
      "Test set: 2000 samples\n",
      "Step 5: Training simplified models...\n",
      "Random Forest F1: 0.986\n",
      "Logistic Regression F1: 0.990\n",
      "Step 6: Saving models...\n",
      "Models saved successfully!\n",
      "Step 7: Creating feature importance visualization...\n",
      "Random Forest F1: 0.986\n",
      "Logistic Regression F1: 0.990\n",
      "Step 6: Saving models...\n",
      "Models saved successfully!\n",
      "Step 7: Creating feature importance visualization...\n",
      "Saved: feature_importance_top10.html and .png\n",
      "Saved: feature_importance_top10.html and .png\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "importance=%{x}<br>feature=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "orientation": "h",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": {
          "bdata": "sdAasOUQ0D/qL1Xi6TTHP2bHE2bl7sQ/GkpVFF6isj+8AMbAOYStP2ugYRC/Nqs/iomefFYoqT8fWH9i4umgP0JOJAuIQaA/k2dI7mFymz8=",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": [
          "complexity_score",
          "ingredient_health_score",
          "processing_claims_count",
          "ingredient_count",
          "healthy_fats_score",
          "category_health_score",
          "ingredient_count",
          "preservatives_score",
          "whole_grains_score",
          "category_frequency"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Top 10 Feature Importances (Random Forest)"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "importance"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "feature"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODELING PIPELINE COMPLETE!\n",
      "Best model: Logistic Regression\n",
      "Best F1 score: 0.990\n",
      "Models saved to RESULTS/models/\n",
      "Visualizations saved to RESULTS/figures/\n"
     ]
    }
   ],
   "source": [
    "# SIMPLIFIED MODELING PIPELINE EXECUTION\n",
    "print(\"MACHINE LEARNING PIPELINE EXECUTION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Step 1: Load engineered features\n",
    "print(\"Step 1: Loading engineered features...\")\n",
    "features_df = pd.read_pickle('../RESULTS/features/engineered_features.pkl')\n",
    "print(f\"Loaded {len(features_df):,} products with {len(features_df.columns)} features\")\n",
    "\n",
    "# Step 2: Create health labels\n",
    "print(\"Step 2: Creating health labels...\")\n",
    "y, health_scores = health_classifier.create_health_labels(features_df)\n",
    "print(f\"Created health labels: {y.sum()} healthy, {len(y)-y.sum()} unhealthy\")\n",
    "\n",
    "# Step 3: Prepare features for modeling\n",
    "feature_columns = [\n",
    "    'brand_product_count', 'brand_category_diversity', 'brand_premium_score',\n",
    "    'preservatives_score', 'artificial_colors_score', 'artificial_sweeteners_score',\n",
    "    'natural_sweeteners_score', 'whole_grains_score', 'healthy_fats_score',\n",
    "    'processing_claims_count', 'ingredient_count', 'complexity_score',\n",
    "    'ingredient_health_score', 'category_frequency', 'category_health_score'\n",
    "]\n",
    "\n",
    "# Filter available features and ensure proper format\n",
    "available_features = [f for f in feature_columns if f in features_df.columns]\n",
    "X = features_df[available_features].fillna(0).astype(float)  # Ensure float type\n",
    "\n",
    "print(f\"Using {len(available_features)} features\")\n",
    "\n",
    "# Step 4: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "\n",
    "# Step 5: Train simplified models (avoiding XGBoost for now)\n",
    "print(\"Step 5: Training simplified models...\")\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_f1 = f1_score(y_test, rf_pred)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "lr_f1 = f1_score(y_test, lr_pred)\n",
    "\n",
    "print(f\"Random Forest F1: {rf_f1:.3f}\")\n",
    "print(f\"Logistic Regression F1: {lr_f1:.3f}\")\n",
    "\n",
    "# Step 6: Save models\n",
    "print(\"Step 6: Saving models...\")\n",
    "joblib.dump(rf_model, models_dir / 'random_forest_model.pkl')\n",
    "joblib.dump(lr_model, models_dir / 'logistic_regression_model.pkl')\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    'random_forest': {'f1': rf_f1, 'accuracy': accuracy_score(y_test, rf_pred)},\n",
    "    'logistic_regression': {'f1': lr_f1, 'accuracy': accuracy_score(y_test, lr_pred)}\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(models_dir / 'model_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Models saved successfully!\")\n",
    "\n",
    "# Step 7: Create feature importance plot\n",
    "print(\"Step 7: Creating feature importance visualization...\")\n",
    "\n",
    "# Get exact feature names from training data\n",
    "feature_names = X_train.columns.tolist()\n",
    "importances = rf_model.feature_importances_[:len(feature_names)]  # Match lengths\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "fig_importance = px.bar(\n",
    "    importance_df.head(10),\n",
    "    x='importance',\n",
    "    y='feature',\n",
    "    orientation='h',\n",
    "    title=\"Top 10 Feature Importances (Random Forest)\"\n",
    ")\n",
    "\n",
    "# Save both formats\n",
    "try:\n",
    "    fig_importance.write_html(figures_dir / 'feature_importance_top10.html')\n",
    "    fig_importance.write_image(figures_dir / 'feature_importance_top10.png', width=1200, height=800)\n",
    "    print(\"Saved: feature_importance_top10.html and .png\")\n",
    "except:\n",
    "    fig_importance.write_html(figures_dir / 'feature_importance_top10.html')\n",
    "    print(\"Saved: feature_importance_top10.html only\")\n",
    "\n",
    "fig_importance.show()\n",
    "\n",
    "print(\"\\nMODELING PIPELINE COMPLETE!\")\n",
    "print(f\"Best model: {'Random Forest' if rf_f1 > lr_f1 else 'Logistic Regression'}\")\n",
    "print(f\"Best F1 score: {max(rf_f1, lr_f1):.3f}\")\n",
    "print(\"Models saved to RESULTS/models/\")\n",
    "print(\"Visualizations saved to RESULTS/figures/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
